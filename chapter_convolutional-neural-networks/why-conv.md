# 完全結合層から畳み込みへ
:label:`sec_why-conv`

今日まで、これまで説明したモデルは、表形式のデータを扱う場合には適切な選択肢のままです。表形式とは、データが例に対応する行と特徴に対応する列で構成されることを意味します。表形式データでは、探索するパターンに特徴間の相互作用が関与すると予想されるかもしれませんが、特徴がどのように相互作用するかについて、*先験的*の構造は想定していません。 

時には、より巧妙な建築物の建設を導くための知識が本当に欠けていることがあります。このような場合、MLPは私たちにできる最善の方法かもしれません。しかし、高次元の知覚データでは、このような構造のないネットワークは扱いにくくなる可能性があります。 

たとえば、猫と犬を区別する実行例に戻りましょう。1メガピクセルの写真の注釈付きデータセットを収集して、データ収集を徹底的に行っているとします。これは、ネットワークへの各入力が 100 万の次元をもつことを意味します。:numref:`subsec_parameterization-cost-fc-layers` における全結合層のパラメータ化コストに関する議論によると、隠れ次元 1000 に積極的に削減しても、$10^6 \times 10^3 = 10^9$ パラメータによって特徴付けられる完全結合層が必要となります。たくさんのGPU、分散最適化の才能、そして並外れた忍耐力がない限り、このネットワークのパラメーターを学ぶことは不可能かもしれません。 

注意深い読者は、1メガピクセルの解像度は必要ないかもしれないという理由で、この議論に反対するかもしれません。ただし、100 万ピクセルでは解決できるかもしれませんが、サイズが 1000 の隠れレイヤーは、画像の適切な表現を学習するために必要な隠れ単位の数を大幅に過小評価しているため、実際のシステムでは依然として数十億のパラメーターが必要になります。さらに、非常に多くのパラメーターをあてはめて分類器を学習するには、膨大なデータセットの収集が必要になる場合があります。しかし、今日、人間とコンピュータの両方が猫と犬を非常によく区別することができ、これらの直感と矛盾しているようです。これは、画像が人間と機械学習モデルの両方で利用できる豊かな構造を示しているからです。畳み込みニューラルネットワーク (CNN) は、自然画像の既知の構造の一部を利用するために機械学習が採用してきた独創的な方法の 1 つです。 

## 不変性

イメージ内のオブジェクトを検出するとします。物体を認識するためにどのような方法を使用する場合でも、画像内の物体の正確な位置を過度に考慮してはならないのは理にかなっているようです。理想的には、私たちのシステムはこの知識を活用すべきです。豚は通常飛行せず、飛行機は通常泳ぎません。それでも、豚は画像の上部に現れたものであると認識する必要があります。ここでは、子供向けゲーム「Where's Waldo」（:numref:`img_waldo`で描かれている）からインスピレーションを得ることができます。このゲームは、アクティビティが溢れる多くの混沌としたシーンで構成されています。Waldoはそれぞれのどこかに現れます, 通常、ありそうもない場所に潜んでいます.読者の目標は彼を見つけることです。彼の特徴的な服装にもかかわらず、注意散漫が多いため、これは驚くほど難しい場合があります。しかし、*Waldoがどのように見えるか*は、*Waldoがどこにあるか*には依存しません。Waldo 検出器で画像をスイープし、各パッチにスコアを割り当てて、パッチに Waldo が含まれている可能性を示すことができます。CNNは、この*空間不変性*の考え方を体系化し、それを利用して、より少ないパラメータで有用な表現を学習する。 

![An image of the "Where's Waldo" game.](../img/where-wally-walker-books.jpg)
:width:`400px`
:label:`img_waldo`

コンピュータビジョンに適したニューラルネットワークアーキテクチャの設計をガイドするいくつかのdesiderataを列挙することで、これらの直感をより具体的にすることができます。 

1. 初期のレイヤーでは、画像内のどこに表示されるかにかかわらず、ネットワークは同じパッチに対して同様に応答するはずです。この原理を*翻訳不変性*と呼びます。
1. ネットワークの最も初期のレイヤーは、離れた領域のイメージの内容に関係なく、ローカル領域に焦点を合わせる必要があります。これが*局所性*の原則です。最終的に、これらのローカル表現を集約して、イメージレベル全体での予測を行うことができます。

これが数学にどのように変換されるか見てみましょう。 

## MLP の制約

はじめに、2 次元イメージ $\mathbf{X}$ を入力とし、その即時の隠れ表現 $\mathbf{H}$ をもつ MLP を数学では行列として、コードでは 2 次元テンソルとして同様に表されます。$\mathbf{X}$ と $\mathbf{H}$ は同じ形状です。それを沈めさせて。今では、入力のみならず、隠れた表現も空間構造をもっていると考えている。 

$[\mathbf{X}]_{i, j}$ と $[\mathbf{H}]_{i, j}$ は、それぞれ入力イメージと隠れ表現の位置 ($i$、$j$) のピクセルを表します。したがって、各隠れユニットが各入力ピクセルから入力を受け取るようにするには、重み行列を使用することから (MLP で以前に行ったように)、パラメーターを 4 次の重みテンソル $\mathsf{W}$ として表すことに切り替えます。$\mathbf{U}$ にバイアスが含まれていると仮定すると、全結合層は次のように形式的に表現できます。 

$$\begin{aligned} \left[\mathbf{H}\right]_{i, j} &= [\mathbf{U}]_{i, j} + \sum_k \sum_l[\mathsf{W}]_{i, j, k, l}  [\mathbf{X}]_{k, l}\\ &=  [\mathbf{U}]_{i, j} +
\sum_a \sum_b [\mathsf{V}]_{i, j, a, b}  [\mathbf{X}]_{i+a, j+b}.\end{aligned},$$

ここで、$\mathsf{W}$ から $\mathsf{V}$ への切り替えは、両方の 4 次のテンソルの係数が 1 対 1 で対応しているため、今のところ完全に表面的なものです。添字 $(k, l)$ を $k = i+a$ と $l = j+b$ のように再インデックスするだけです。つまり、$[\mathsf{V}]_{i, j, a, b} = [\mathsf{W}]_{i, j, i+a, j+b}$ を設定します。インデックス $a$ と $b$ は正と負の両方のオフセットにわたって実行され、イメージ全体をカバーします。隠れ表示 $[\mathbf{H}]_{i, j}$ の任意の位置 ($i$、$j$) について、$x$ のピクセルを $(i, j)$ を中心とし、$[\mathsf{V}]_{i, j, a, b}$ で重みを付けて合計してその値を計算します。 

### 翻訳不変性

ここで、上で確立した第1の原則、翻訳不変性を呼びかけましょう。これは、入力 $\mathbf{X}$ のシフトが、隠れ表示 $\mathbf{H}$ のシフトにつながるだけであることを意味します。これは $\mathsf{V}$ と $\mathbf{U}$ が実際に $(i, j)$ に依存しない場合のみ可能です。つまり、$[\mathsf{V}]_{i, j, a, b} = [\mathbf{V}]_{a, b}$ があり、$\mathbf{U}$ が定数、たとえば $u$ である場合のみです。その結果、$\mathbf{H}$ の定義を簡略化できます。 

$$[\mathbf{H}]_{i, j} = u + \sum_a\sum_b [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.$$

これは*畳み込み*です！$[\mathbf{H}]_{i, j}$ という値を得るために、位置 $(i, j)$ の近傍にある $(i+a, j+b)$ のピクセルに係数 $[\mathbf{V}]_{a, b}$ を効果的に加重しています。$[\mathbf{V}]_{a, b}$ は $[\mathsf{V}]_{i, j, a, b}$ よりはるかに少ない係数しか必要としないことに注意してください。これは、イメージ内の位置に依存しなくなったためです。私たちは大きな進歩を遂げました！ 

###  局所性

さて、第二の原則、局所性を呼び起こしましょう。上記の動機として、$[\mathbf{H}]_{i, j}$ で何が起こっているのかを評価するために関連情報を収集するために、場所 $(i, j)$ からそれほど遠くを見る必要はないと考えています。つまり、$|a|> \Delta$ または $|b| > \Delta$ の範囲外では $[\mathbf{V}]_{a, b} = 0$ を設定する必要があります。同様に、$[\mathbf{H}]_{i, j}$ を次のように書き換えることができます。 

$$[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.$$
:eqlabel:`eq_conv-layer`

:eqref:`eq_conv-layer` は、一言で言えば、*畳み込み層* であることに注意してください。
*畳み込みニューラルネットワーク* (CNN)
は、畳み込み層を含むニューラルネットワークの特別なファミリーです。深層学習の研究コミュニティでは、$\mathbf{V}$ は*畳み込みカーネル*、*フィルター*、または単に層の*重み* と呼ばれ、多くの場合学習可能なパラメーターです。ローカルリージョンが小さい場合、完全に接続されたネットワークと比較して大きな違いが生じる可能性があります。以前は、画像処理ネットワークで 1 つのレイヤーだけを表すには数十億のパラメーターが必要でしたが、入力または非表示の表現の次元を変更することなく、通常は数百個のパラメーターしか必要としません。このパラメータの大幅な削減に支払われた代償は、機能が翻訳不変になり、隠れたアクティベーションの値を決定する際にレイヤーがローカル情報のみを組み込むことができることです。すべての学習は帰納的バイアスを課すことにかかっています。そのバイアスが現実と一致すれば、目に見えないデータにうまく一般化するサンプル効率の良いモデルが得られます。しかしもちろん、画像が翻訳不変でないことが判明した場合など、これらのバイアスが現実と一致しない場合、モデルはトレーニングデータに適合させるのに苦労する可能性があります。 

## 畳み込み

先に進む前に、上記の演算が畳み込みと呼ばれる理由を簡単に確認しておく必要があります。数学では、$f, g: \mathbb{R}^d \to \mathbb{R}$ などの 2 つの関数間の*畳み込み* は次のように定義されます。 

$$(f * g)(\mathbf{x}) = \int f(\mathbf{z}) g(\mathbf{x}-\mathbf{z}) d\mathbf{z}.$$

つまり、1 つの関数が「反転」されて $\mathbf{x}$ だけシフトされたときの $f$ と $g$ の間のオーバーラップを測定します。離散的な物体があるときはいつでも、積分は和に変わります。たとえば、インデックスが $\mathbb{Z}$ を超える平方加算可能な無限次元ベクトルのセットからのベクトルでは、次の定義が得られます。 

$$(f * g)(i) = \sum_a f(a) g(i-a).$$

2 次元テンソルの場合、$f$ の場合は $(a, b)$、$g$ の場合は $(i-a, j-b)$ のインデックスがそれぞれ対応する和になります。 

$$(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i-a, j-b).$$
:eqlabel:`eq_2d-conv-discrete`

これは :eqref:`eq_conv-layer` と似ていますが、1 つの大きな違いがあります。$(i+a, j+b)$ ではなく、差分を代わりに使用しています。ただし、:eqref:`eq_conv-layer` と :eqref:`eq_2d-conv-discrete` の間の表記法を常に一致させることができるので、この区別はほとんど表面的なものであることに注意してください。:eqref:`eq_conv-layer` の元の定義は、*相互相関* をより適切に記述しています。これについては、次のセクションで説明します。 

## 「ウォーリーをさがせ」再訪

Waldo検出器に戻って、これがどのように見えるか見てみましょう。畳み込み層は :numref:`fig_waldo_mask` で示されるように、フィルター $\mathsf{V}$ に従って、所定のサイズのウィンドウを選択し、強度の重みを付けます。「ウォルドネス」が最も高い場所で、隠れ層表現のピークを見つけるために、モデルを学ぶことを目指すかもしれません。 

![Detect Waldo.](../img/waldo-mask.jpg)
:width:`400px`
:label:`fig_waldo_mask`

### チャネル
:label:`subsec_why-conv-channels`

このアプローチには一つだけ問題があります。これまでのところ、画像は赤、緑、青の3つのチャンネルで構成されていることを無視していました。実際には、イメージは 2 次元のオブジェクトではなく、高さ、幅、チャネルによって特徴付けられる 3 次テンソルです。たとえば、形状は $1024 \times 1024 \times 3$ ピクセルです。これらの軸の最初の 2 つは空間リレーションシップに関係しますが、3 番目の軸は各ピクセル位置に多次元表現を割り当てていると見なすことができます。したがって、$\mathsf{X}$ を $[\mathsf{X}]_{i, j, k}$ としてインデックス付けします。畳み込みフィルターは、それに応じて適応しなければなりません。$[\mathbf{V}]_{a,b}$ の代わりに $[\mathsf{V}]_{a,b,c}$ になりました。 

さらに、入力が三次テンソルで構成されているように、隠れた表現を三次テンソル $\mathsf{H}$ と同様に定式化するのは良い考えです。言い換えると、各空間位置に対応する隠れ表現を 1 つだけ持つのではなく、各空間位置に対応する隠れ表現のベクトル全体が必要となります。隠れた表現は、互いの上に積み重ねられた複数の 2 次元グリッドで構成されていると考えることができます。入力と同様に、これらは*チャンネル*と呼ばれることもあります。これらは*フィーチャマップ* とも呼ばれ、それぞれが空間化された一連の学習済みフィーチャを後続のレイヤーに提供するからです。直感的に、入力に近い下位のレイヤーでは、一部のチャンネルがエッジを認識するように特化され、他のチャンネルはテクスチャを認識できると想像できるかもしれません。 

入力 ($\mathsf{X}$) と隠れ表示 ($\mathsf{H}$) の両方で複数のチャンネルをサポートするために、$\mathsf{V}$:$[\mathsf{V}]_{a, b, c, d}$ に 4 番目の座標を追加できます。すべてをまとめると、次のようになります。 

$$[\mathsf{H}]_{i,j,d} = \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} \sum_c [\mathsf{V}]_{a, b, c, d} [\mathsf{X}]_{i+a, j+b, c},$$
:eqlabel:`eq_conv-layer-channels`

$d$ は、隠し表示 $\mathsf{H}$ の出力チャンネルにインデックスを付けます。後続の畳み込み層は、3 次のテンソル $\mathsf{H}$ を入力として受け取ります。より一般的には :eqref:`eq_conv-layer-channels` は複数チャンネルの畳み込み層の定義で、$\mathsf{V}$ は層のカーネルまたはフィルターです。 

対処する必要のある操作はまだたくさんあります。例えば、画像にWaldo*Anywhere*があるかどうかなど、すべての隠れた表現を1つの出力にまとめる方法を理解する必要があります。また、物事を効率的に計算する方法、複数の層をどのように組み合わせるか、適切な活性化関数、そして実際に有効なネットワークを生成するための合理的な設計選択を行う方法を決定する必要があります。これらの問題については、この章の残りの部分で取り上げます。 

## [概要

* イメージ内の平行移動不変性は、イメージのすべてのパッチが同じ方法で処理されることを意味します。
* 局所性とは、近傍のピクセルが対応する隠れ表現の計算に使用されることを意味します。
* イメージ処理では、畳み込み層では通常、完全に接続された層よりもはるかに少ないパラメーターしか必要としません。
* CNNS は、畳み込み層を含む特殊なニューラルネットワークファミリーです。
* 入力と出力のチャネルにより、モデルは各空間位置でイメージの複数の側面をキャプチャできます。

## 演習

1. 畳み込みカーネルのサイズが $\Delta = 0$ であると仮定します。この場合、畳み込みカーネルがチャネルセットごとに独立して MLP を実装することを示します。
1. 翻訳不変性が結局良い考えではないのはなぜですか？
1. 画像の境界にあるピクセル位置に対応する隠れた表現をどのように扱うかを決めるとき、どのような問題に対処しなければならないでしょうか？
1. オーディオ用の類似の畳み込み層について説明する。
1. 畳み込み層はテキストデータにも適用できると思いますか？なぜ、なぜそうではないのですか？
1. $f * g = g * f$であることを証明しろ

[Discussions](https://discuss.d2l.ai/t/64)
