# 畳み込みニューラルネットワーク
:label:`chap_cnn`

以前の章では、各例がピクセルの2次元グリッドで構成されるイメージデータについて考え出しました。白黒画像とカラー画像のどちらを扱うかによって、各ピクセルの位置はそれぞれ 1 つまたは複数の数値に関連付けられます。これまで、この豊かな構造に対する私たちの対処方法は非常に満足のいくものではありませんでした。各画像の空間構造を 1 次元ベクトルに平坦化し、完全に接続された MLP を介して供給することで、単純に破棄しました。これらのネットワークは特徴の順序に対して不変であるため、ピクセルの空間構造に対応する次数を維持するか、MLP のパラメーターをあてはめる前に計画行列の列を並べ替えるかに関係なく、同様の結果を得ることができます。画像データから学習するための効率的なモデルを構築するために、近傍のピクセルは一般的に互いに関連しているという事前の知識を活用することが望ましい。  

この章では、まさにこの目的のために設計された強力なニューラルネットワークファミリーである*畳み込みニューラルネットワーク* (CNN) について紹介します。CNNベースのアーキテクチャは現在、コンピュータビジョンの分野で広く普及しており、このアプローチを土台にしなければ、商用アプリケーションを開発したり、画像認識、物体検出、セマンティックセグメンテーションに関連する競争に参加したりする人はほとんどいないほどに支配的になっています。 

現代のCNNは、口語的に呼ばれているように、生物学、群論、および実験的ないじくり回しの健康的な線量からのインスピレーションにデザインを負っています。CNN は、正確なモデルを実現するためのサンプル効率に加えて、完全接続アーキテクチャよりも必要なパラメーターが少なく、畳み込みが GPU コア間で並列化しやすいため、計算効率が高い傾向があります。その結果、実践者は可能な限りCNNを適用することが多く、リカレントニューラルネットワークが従来使用されていたオーディオ、テキスト、時系列解析などの一次元配列構造を持つタスクにおいても、CNNは信頼できる競合企業として浮上しています。CNNの巧妙な適応により、グラフ構造化データとレコメンダーシステムにも影響するようになりました。 

まず、すべての畳み込みネットワークのバックボーンを構成する基本演算について説明します。これには、畳み込み層そのもの、パディングやストライドなどの核心的な詳細、隣接する空間領域にまたがる情報の集約に使用されるプーリング層、各層での複数チャネルの使用、最新のアーキテクチャの構造に関する注意深い議論が含まれます。この章の締めくくりは、現代のディープラーニングが登場するずっと前から、初めて導入に成功した畳み込みネットワークであるLeNetの完全な実例を示しています。次の章では、現代の実務家によって一般的に使用されているテクニックのほとんどをデザインが表す比較的最近のCNNアーキテクチャの完全な実装に飛び込みます。

```toc
:maxdepth: 2

why-conv
conv-layer
padding-and-strides
channels
pooling
lenet
```
