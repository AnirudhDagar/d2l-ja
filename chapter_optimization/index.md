# 最適化アルゴリズム
:label:`chap_optimization`

この時点までに本を順番に読んでいれば、ディープラーニングモデルのトレーニングにはすでにいくつかの最適化アルゴリズムが使用されています。これらは、トレーニングセットで評価されたとおりに、モデルパラメーターの更新を継続し、損失関数の値を最小化することを可能にするツールでした。実際、単純な設定で目的関数を最小化するための最適化をブラックボックスデバイスとして扱うことに満足している人は、そのような手順の呪文 (「SGD」や「Adam」などの名前を持つ) が数多く存在するという知識に満足しているかもしれません。 

しかし、うまくやるには、ある程度の深い知識が必要です。最適化アルゴリズムはディープラーニングにとって重要です。一方で、複雑なディープラーニングモデルのトレーニングには、数時間、数日、さらには数週間かかることがあります。最適化アルゴリズムのパフォーマンスは、モデルの学習効率に直接影響します。一方、さまざまな最適化アルゴリズムの原理とそのハイパーパラメーターの役割を理解することで、ハイパーパラメーターを的を絞った方法で調整し、ディープラーニングモデルのパフォーマンスを向上させることができます。 

この章では、一般的なディープラーニング最適化アルゴリズムについて詳しく説明します。ディープラーニングで発生する最適化問題のほとんどは、*nonconvex* です。とはいえ、*凸型*問題の文脈におけるアルゴリズムの設計と解析は、非常に有益であることが証明されています。そのため、この章には凸最適化の入門書と、凸目的関数に対する非常に単純な確率的勾配降下アルゴリズムの証明が含まれています。

```toc
:maxdepth: 2

optimization-intro
convexity
gd
sgd
minibatch-sgd
momentum
adagrad
rmsprop
adadelta
adam
lr-scheduler
```
