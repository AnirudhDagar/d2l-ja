# 最適化とディープラーニング

このセクションでは、最適化とディープラーニングの関係、およびディープラーニングで最適化を使用する際の課題について説明します。ディープラーニング問題では、通常、最初に*損失関数* を定義します。損失関数が得られたら、最適化アルゴリズムを使用して損失を最小限に抑えることができます。最適化では、損失関数は最適化問題の*目的関数*と呼ばれることがよくあります。伝統と慣例により、ほとんどの最適化アルゴリズムは*最小化*に関係しています。目標を最大化する必要がある場合、単純な解決策があります。目標の記号を反転させるだけです。 

## 最適化の目標

最適化はディープラーニングの損失関数を最小化する方法を提供しますが、本質的には最適化とディープラーニングの目標は根本的に異なります。前者は主に目的を最小化することに関係し、後者は有限量のデータから適切なモデルを見つけることに関係します。:numref:`sec_model_selection` では、これら 2 つの目標の違いについて詳しく説明しました。たとえば、学習誤差と汎化誤差は一般的に異なります。最適化アルゴリズムの目的関数は通常、学習データセットに基づく損失関数であるため、最適化の目的は学習誤差を減らすことです。ただし、ディープラーニング (より広い意味では統計的推論) の目標は、汎化誤差を減らすことです。後者を達成するには、最適化アルゴリズムを使用して学習誤差を減らすことに加え、過適合にも注意する必要があります。

```{.python .input}
%matplotlib inline
from d2l import mxnet as d2l
from mpl_toolkits import mplot3d
from mxnet import np, npx
npx.set_np()
```

```{.python .input}
#@tab pytorch
%matplotlib inline
from d2l import torch as d2l
import numpy as np
from mpl_toolkits import mplot3d
import torch
```

```{.python .input}
#@tab tensorflow
%matplotlib inline
from d2l import tensorflow as d2l
import numpy as np
from mpl_toolkits import mplot3d
import tensorflow as tf
```

前述のさまざまな目標を説明するために、経験的リスクとリスクについて考えてみましょう。:numref:`subsec_empirical-risk-and-risk` で説明したように、経験的リスクはトレーニングデータセットの平均損失であり、リスクはデータ母集団全体で予想される損失です。以下では、リスク関数 `f` と経験的リスク関数 `g` の 2 つの関数を定義します。有限の量のトレーニングデータしかないと仮定します。その結果、`g` は `f` よりも滑らかではありません。

```{.python .input}
#@tab all
def f(x):
    return x * d2l.cos(np.pi * x)

def g(x):
    return f(x) + 0.2 * d2l.cos(5 * np.pi * x)
```

以下のグラフは、トレーニングデータセットの経験的リスクの最小値が、最小のリスク（汎化誤差）とは異なる場所にある可能性があることを示しています。

```{.python .input}
#@tab all
def annotate(text, xy, xytext):  #@save
    d2l.plt.gca().annotate(text, xy=xy, xytext=xytext,
                           arrowprops=dict(arrowstyle='->'))

x = d2l.arange(0.5, 1.5, 0.01)
d2l.set_figsize((4.5, 2.5))
d2l.plot(x, [f(x), g(x)], 'x', 'risk')
annotate('min of\nempirical risk', (1.0, -1.2), (0.5, -1.1))
annotate('min of risk', (1.1, -1.05), (0.95, -0.5))
```

## ディープラーニングにおける最適化の課題

この章では、モデルの汎化誤差ではなく、目的関数を最小化する最適化アルゴリズムの性能に特に焦点を当てます。:numref:`sec_linear_regression` では、最適化問題において解析解と数値解を区別しました。ディープラーニングでは、ほとんどの目的関数が複雑で、解析解がありません。その代わり、数値最適化アルゴリズムを使わなければなりません。この章の最適化アルゴリズムはすべてこのカテゴリに分類されます。 

ディープラーニングの最適化には多くの課題があります。最も厄介なものには、局所的最小値、サドルポイント、消失グラデーションなどがあります。それらを見てみよう。 

### 局所的極小値

目的関数 $f(x)$ について、$x$ の $f(x)$ の値が $x$ 付近の他のポイントにおける $f(x)$ の値よりも小さい場合、$f(x)$ は局所的最小値になる可能性があります。$x$ の $f(x)$ の値が領域全体にわたる目的関数の最小値である場合、$f(x)$ はグローバル最小値です。 

たとえば、次の関数が与えられたとします。 

$$f(x) = x \cdot \text{cos}(\pi x) \text{ for } -1.0 \leq x \leq 2.0,$$

この関数の局所的最小値と大域的最小値を近似することができます。

```{.python .input}
#@tab all
x = d2l.arange(-1.0, 2.0, 0.01)
d2l.plot(x, [f(x), ], 'x', 'f(x)')
annotate('local minimum', (-0.3, -0.25), (-0.77, -1.0))
annotate('global minimum', (1.1, -0.95), (0.6, 0.8))
```

ディープラーニングモデルの目的関数には通常、多くの局所最適値があります。最適化問題の数値解が局所最適値に近い場合、最後の反復で得られる数値解は、目的関数の解の勾配がゼロに近づくかゼロになるにつれて、*globally* ではなく、*locally* の目的関数を最小化することしかできません。ある程度のノイズだけが、ローカル最小値からパラメータをノックアウトする可能性があります。実際、これはミニバッチの確率的勾配降下法の有益な特性の 1 つであり、ミニバッチでの勾配の自然変動により、局所的最小値からパラメーターを取り除くことができます。 

### サドルポイント

局所的最小値以外に、サドルポイントはグラデーションが消失するもう 1 つの理由です。*サドルポイント* は、関数のすべての勾配が消滅するが、大域的最小値でも局所的最小値でもない任意の位置です。$f(x) = x^3$ という関数を考えてみましょう。その一次導関数と二次導関数は$x=0$で消滅する。最適化は最小値ではありませんが、この時点で最適化が停止することがあります。

```{.python .input}
#@tab all
x = d2l.arange(-2.0, 2.0, 0.01)
d2l.plot(x, [x**3], 'x', 'f(x)')
annotate('saddle point', (0, -0.2), (-0.52, -5.0))
```

次の例に示すように、高次元のサドルポイントはさらに陰気です。$f(x, y) = x^2 - y^2$ という関数を考えてみましょう。サドルポイントは $(0, 0)$ です。これは $y$ に対する最大値であり、$x$ に対する最小値です。さらに、それはサドルのように見え、この数学的性質がその名前の由来となった場所です。

```{.python .input}
#@tab all
x, y = d2l.meshgrid(
    d2l.linspace(-1.0, 1.0, 101), d2l.linspace(-1.0, 1.0, 101))
z = x**2 - y**2

ax = d2l.plt.figure().add_subplot(111, projection='3d')
ax.plot_wireframe(x, y, z, **{'rstride': 10, 'cstride': 10})
ax.plot([0], [0], [0], 'rx')
ticks = [-1, 0, 1]
d2l.plt.xticks(ticks)
d2l.plt.yticks(ticks)
ax.set_zticks(ticks)
d2l.plt.xlabel('x')
d2l.plt.ylabel('y');
```

関数の入力は $k$ 次元のベクトルで、その出力はスカラーであると仮定します。したがって、ヘッセ行列は $k$ 個の固有値をもちます ([online appendix on eigendecompositions](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html) を参照)。関数の解は、局所的最小値、局所的最大値、または関数の勾配がゼロの位置にあるサドルポイントになります。 

* 勾配がゼロの位置にある関数のヘッセ行列の固有値がすべて正の場合、関数の局所的最小値が得られます。
* 勾配ゼロの位置にある関数のヘッセ行列の固有値がすべて負の場合、関数には局所的最大値があります。
* 勾配ゼロの位置にある関数のヘッセ行列の固有値が負で正の場合、この関数のサドルポイントが得られます。

高次元の問題では、固有値の少なくとも*一部*が負になる可能性が非常に高くなります。これにより、サドルポイントが局所的最小値よりも高くなります。凸型を導入する際には、次のセクションで、この状況の例外をいくつか説明します。つまり、凸関数とは、ヘッシアンの固有値が決して負にならない関数です。しかし、残念なことに、ほとんどのディープラーニングの問題はこのカテゴリには当てはまりません。とはいえ、最適化アルゴリズムを研究するには素晴らしいツールです。 

### 消失するグラデーション

おそらく遭遇する最も陰湿な問題は、消失する勾配でしょう。:numref:`subsec_activation-functions` でよく使われている活性化関数とその派生関数を思い出してください。たとえば、関数 $f(x) = \tanh(x)$ を最小化し、たまたま $x = 4$ から開始したとします。ご覧のとおり、$f$ の勾配はゼロに近いです。具体的には $f'(x) = 1 - \tanh^2(x)$、つまり $f'(4) = 0.0013$ です。その結果、最適化は進歩する前に長い間行き詰まってしまいます。これは、ReLU アクティベーション関数が導入される前にディープラーニングモデルのトレーニングが非常に困難であった理由の 1 つであることが判明しました。

```{.python .input}
#@tab all
x = d2l.arange(-2.0, 5.0, 0.01)
d2l.plot(x, [d2l.tanh(x)], 'x', 'f(x)')
annotate('vanishing gradient', (4, 1), (2, 0.0))
```

これまで見てきたように、ディープラーニングの最適化には多くの課題があります。幸いなことに、優れたパフォーマンスを発揮し、初心者でも使いやすい堅牢なアルゴリズムがあります。さらに、*the*最適なソリューションを見つける必要はありません。局所最適解あるいは近似解は依然として非常に有用である。 

## [概要

* 学習誤差を最小化しても、汎化誤差を最小化するための最適なパラメーターセットを見つけることが保証されるわけではありません。
* 最適化問題には多数の局所的最小値がある場合があります。
* 通常、問題は凸状ではないため、サドルポイントがさらに多くなることがあります。
* グラデーションが消失すると、最適化が停止することがあります。多くの場合、問題のパラメータ再設定が役立ちます。パラメーターを適切に初期化することも、有益です。

## 演習

1. たとえば、隠れ層に $d$ 次元の隠れ層が 1 つあり、出力が 1 つの単純な MLP を考えてみます。局所的最小値に対して少なくとも$dがあることを示してください！同じように動作する$同等のソリューション。
1. 対称乱数行列 $\mathbf{M}$ があり、エントリ $M_{ij} = M_{ji}$ はそれぞれ何らかの確率分布 $p_{ij}$ から抽出されたものと仮定します。さらに、$p_{ij}(x) = p_{ij}(-x)$、つまり分布が対称であると仮定します (詳細は :cite:`Wigner.1958` を参照)。
    1. 固有値を超える分布も対称であることを証明する。つまり、固有ベクトル $\mathbf{v}$ について、関連する固有値 $\lambda$ が $P(\lambda > 0) = P(\lambda < 0)$ を満たす確率です。
    1. 上記が$P(\lambda > 0) = 0.5$を暗示しないのはなぜですか？
1. ディープラーニングの最適化には、他にどのような課題が考えられますか？
1. (実際の) サドルに (実際の) ボールをバランスさせたいとします。
    1. なんでこんなに難しいの？
    1. この効果を最適化アルゴリズムにも利用できますか？

:begin_tab:`mxnet`
[Discussions](https://discuss.d2l.ai/t/349)
:end_tab:

:begin_tab:`pytorch`
[Discussions](https://discuss.d2l.ai/t/487)
:end_tab:

:begin_tab:`tensorflow`
[Discussions](https://discuss.d2l.ai/t/489)
:end_tab:
