# 環境と流通シフト

これまでのセクションでは、さまざまなデータセットにモデルを適合させながら、機械学習の実践的なアプリケーションを数多く取り上げました。それでも、そもそもデータがどこから来るのか、それともモデルからの出力を最終的にどう処理するのかを考えるのをやめませんでした。データを所有している機械学習の開発者は、こうした根本的な問題を考えるために立ち止まることなくモデルの開発を急ぐことが多々あります。 

失敗した機械学習の導入の多くは、このパターンにさかのぼることができます。モデルは、テストセットの精度で測定すると驚異的なパフォーマンスを発揮しているように見えますが、データの分布が突然変化すると、展開時に壊滅的に失敗することがあります。もっと狡猾に言えば、モデルの展開そのものがデータ分布を混乱させる触媒になることもあります。たとえば、ローンの返済者と債務不履行を予測するモデルをトレーニングしたところ、申請者の履物の選択が債務不履行のリスクと関連していることが判明したとします (オックスフォードは返済を示し、スニーカーはデフォルトを示します)。その後、オックスフォードを着用しているすべての応募者に融資を行い、スニーカーを着用しているすべての応募者を拒否する傾向があるかもしれません。. 

この場合、パターン認識から意思決定への慎重な飛躍や、環境を批判的に考慮しなかったことは、悲惨な結果をもたらす可能性があります。手始めに、私たちが履物に基づいて意思決定を始めるとすぐに、顧客は自分の行動に追いつき、変化しました。やがて、すべての応募者はオックスフォードを着用し、信用力が同時に向上することはありません。機械学習の多くのアプリケーションには同様の問題がたくさんあるため、この点を理解してください。モデルベースの意思決定を環境に導入すると、モデルが壊れる可能性があります。 

これらのトピックを1つのセクションで完全に扱うことはできませんが、ここでは共通の懸念を明らかにし、これらの状況を早期に発見し、被害を軽減し、責任を持って機械学習を使用するために必要な批判的思考を刺激することを目指しています。解決策の中には、単純なもの（「正しい」データを求める）もの、技術的に難しいもの（強化学習システムを実装すること）、統計的予測の領域から完全に踏み出して、その倫理的応用に関する難しい哲学的疑問に取り組むことが求められるものもあります。アルゴリズム。 

## 流通シフトの種類

まず、データ分布が変化する可能性のあるさまざまな方法と、モデルのパフォーマンスを改善するために何ができるかを考慮して、パッシブ予測の設定に固執します。ある古典的な設定では、トレーニングデータは分布 $p_S(\mathbf{x},y)$ からサンプリングされたものの、検定データは異なる分布 $p_T(\mathbf{x},y)$ から抽出されたラベルのない例で構成されると仮定します。すでに、私たちは冷静な現実に立ち向かわなければなりません。$p_S$ と $p_T$ の相互関係についての仮定がなければ、ロバストな分類器を学習することは不可能です。 

犬と猫を区別したい二項分類問題を考えてみましょう。分布が任意の方法でシフトできる場合、入力に対する分布は一定のままである病理学的ケース $p_S(\mathbf{x}) = p_T(\mathbf{x})$ を許可しますが、ラベルはすべて反転します ($p_S(y | \mathbf{x}) = 1 - p_T(y | \mathbf{x})$)。言い換えれば、将来、すべての「猫」が犬になり、以前「犬」と呼ばれていたものが今や猫であると神が突然決定されるなら、入力$p(\mathbf{x})$の分布に変化がなければ、この設定を分布がまったく変化しなかった設定と区別できないでしょう。 

幸いなことに、データが将来どのように変化するかについての制限された仮定の下で、原理アルゴリズムはシフトを検出し、場合によってはオンザフライで適応し、元の分類器の精度を向上させることができます。 

### 共変量シフト

分布シフトのカテゴリの中でも、共変量シフトが最も広く研究されている可能性があります。ここでは、入力の分布は時間とともに変化する可能性がありますが、ラベル付け関数、つまり条件付き分布 $P(y \mid \mathbf{x})$ は変化しないと仮定します。共変量 (特徴) の分布のシフトにより問題が生じるため、統計学者はこれを*共変量シフト*と呼んでいます。因果関係を呼び出さずに分布シフトについて推論できる場合もありますが、$\mathbf{x}$ が $y$ を引き起こすと考えられる設定では、共変量シフトが自然な仮定であることに注意してください。 

猫と犬を区別するという課題を考えてみましょう。私たちのトレーニングデータは :numref:`fig_cat-dog-train` の種類のイメージで構成されているかもしれません。 

![Training data for distinguishing cats and dogs.](../img/cat-dog-train.svg)
:label:`fig_cat-dog-train`

テスト時には :numref:`fig_cat-dog-test` で画像を分類するよう求められます。 

![Test data for distinguishing cats and dogs.](../img/cat-dog-test.svg)
:label:`fig_cat-dog-test`

トレーニングセットは写真で構成され、テストセットには漫画のみが含まれます。テストセットとは大幅に異なる特性を持つデータセットでトレーニングを行うと、新しい領域への適応方法に関する一貫した計画がないと、問題を引き起こす可能性があります。 

### ラベルシフト

*ラベル shift* は逆問題を表します。
ここでは、ラベル marginal $P(y)$ は変更できるが、クラス条件付き分布 $P(\mathbf{x} \mid y)$ はドメイン間で固定されたままであると仮定します。$y$ が $\mathbf{x}$ を引き起こすと考えられる場合、ラベルシフトは妥当な仮定です。たとえば、診断の相対的な有病率が時間とともに変化している場合でも、症状 (または他の症状) を考慮して診断を予測したい場合があります。病気は症状を引き起こすため、ここではラベルシフトが適切な仮定です。縮退したケースでは、ラベルシフトと共変量シフトの仮定が同時に成立することがあります。たとえば、ラベルが決定論的である場合、$y$ が $\mathbf{x}$ を引き起こしても、共変量シフトの仮定は満たされます。興味深いことに、このような場合、ラベルシフトの仮定から流れ出るメソッドを使用する方が有利な場合がよくあります。これは、ディープラーニングでは高次元になりがちな入力のように見えるオブジェクトとは対照的に、これらのメソッドではラベルのように見えるオブジェクト (通常は低次元) を操作する傾向があるためです。 

### コンセプトシフト

また、ラベルの定義そのものが変わる可能性がある場合に発生する「コンセプトシフト」という関連する問題に遭遇することもあります。これは奇妙に聞こえる-*猫*は*猫*だ、いや？ただし、他のカテゴリは時間の経過とともに使用量が変化することがあります。精神疾患の診断基準、ファッショナブルなもの、役職はすべて、かなりの量の概念シフトの対象となります。:numref:`fig_popvssoda`に示すように、データのソースを地理的にシフトして米国内を移動すると、*ソフトドリンク*の名前の分布に関してかなりの概念シフトが見られることが分かります。 

![Concept shift on soft drink names in the United States.](../img/popvssoda.png)
:width:`400px`
:label:`fig_popvssoda`

機械翻訳システムを構築する場合、$P(y \mid \mathbf{x})$ の配布は、所在地によって異なる可能性があります。この問題は見つけにくい場合があります。シフトは時間的または地理的な意味で徐々にしか起こらないという知識を活用したいと思うかもしれません。 

## 流通シフトの例

形式主義とアルゴリズムを掘り下げる前に、共変量や概念シフトが明らかではないかもしれない具体的な状況について議論することができます。 

### 医療診断

がんを検出するアルゴリズムを設計するとします。健康な人や病気の人からデータを収集し、アルゴリズムをトレーニングします。それはうまく機能し、高い精度を提供し、医療診断のキャリアを成功させる準備ができていると結論付けます。
*そんなに早くない*

トレーニングデータを生成した分布と、実際に遭遇する分布は大きく異なる可能性があります。これは、私たち（作家）の何人かが何年も前に働いていた不幸なスタートアップに起こりました。彼らは、主に高齢男性に影響を及ぼす病気の血液検査を開発しており、患者から採取した血液サンプルを用いて血液検査を研究したいと考えていました。しかし、健康な男性から血液サンプルを採取することは、すでにシステム内にいる病気の患者よりもかなり困難です。これを補うために、スタートアップは大学のキャンパスの学生から献血を募り、テストの開発における健康的なコントロールとして機能しました。次に、病気を検出するための分類器を構築するのを手伝ってもらえないかと尋ねました。 

彼らに説明したように、健康なコホートと病気のコホートをほぼ完璧な精度で区別するのは確かに簡単です。ただし、これは、被験者の年齢、ホルモンレベル、身体活動、食事、アルコール消費量、および病気に関係のない多くの要因が異なるためです。これは実際の患者には当てはまりそうにありませんでした。それらのサンプリング手順により、極端な共変量シフトが発生することが予想されます。さらに、このケースは従来の方法で修正できる可能性は低かった。要するに、彼らはかなりの金額を浪費した。 

### 自動運転車

ある企業が、自動運転車の開発に機械学習を活用したいと考えていたとします。ここで重要なコンポーネントの1つは、路側検出器です。実際のアノテーション付きデータは入手にコストがかかるため、ゲームレンダリングエンジンからの合成データを追加のトレーニングデータとして使用するという (賢明で疑わしい) アイデアがありました。これは、レンダリングエンジンから引き出された「テストデータ」に対して非常にうまく機能しました。悲しいかな、実際の車の中では災害でした。結局のところ、道端は非常にシンプルなテクスチャでレンダリングされていました。さらに重要なのは、路側が*すべて*同じ*テクスチャでレンダリングされ、路側検出器がこの「特徴」について非常に迅速に認識したことです。 

米軍が森林内の戦車を最初に検出しようとしたときにも同様のことが起こりました。彼らは戦車なしで森の空中写真を撮り、戦車を森に追い込み、別の写真を撮りました。分類器は*完全に*機能しているように見えました。残念ながら、影のある木と影のない木を区別する方法を学んだだけでした。最初の写真は早朝、2番目の写真は正午に撮影されました。 

### 非定常分布

分布の変化が遅く (*非定常分布* とも呼ばれる)、モデルが適切に更新されない場合は、さらに微妙な状況が発生します。以下は代表的なケースです。 

* 私たちはコンピュテーショナル広告モデルをトレーニングし、それを頻繁に更新することに失敗しています (例えば、iPad と呼ばれるあいまいな新しいデバイスが発売されたばかりであることを組み込むのを忘れたなど)。
* スパムフィルターを構築します。これは、これまでに見たすべてのスパムを検出するのに適しています。しかし、その後、スパマーは賢明になり、これまでに見たことのない新しいメッセージを作成します。
* 製品レコメンデーションシステムを構築します。冬の間は機能しますが、クリスマスの後もずっとサンタの帽子を推薦し続けます。

### その他の逸話

* 顔検出器を作ります。すべてのベンチマークでうまく機能します。残念ながら、テストデータでは失敗します。問題のある例は、顔が画像全体を塗りつぶすクローズアップです（トレーニングセットにはそのようなデータはありませんでした）。
* 米国市場向けのWeb検索エンジンを構築し、英国に展開したいと考えています。
* 画像分類器を学習させるには、大規模なデータセットをコンパイルします。このデータセットでは、多数のクラスの各クラスが 1000 個のカテゴリをデータセット内で等しく表し、それぞれ 1000 個の画像で表されます。次に、写真の実際のラベル配布が明らかに不均一である現実世界にシステムを展開します。

## 分配シフトの訂正

すでに説明したように、学習分布と検定分布 $P(\mathbf{x}, y)$ が異なるケースが多くあります。場合によっては、共変量、ラベル、または概念のシフトにもかかわらず、ラッキーになり、モデルが機能します。それ以外の場合は、シフトに対処するための原則的な戦略を採用することで、より良い結果を得ることができます。このセクションの残りの部分では、より技術的な内容が大きくなります。この資料は後の概念の前提条件ではないため、せっかちな読者は次のセクションに進むことができます。 

### 経験的リスクとリスク
:label:`subsec_empirical-risk-and-risk`

まず、モデルトレーニング中に何が起きているのかを考えてみましょう。トレーニングデータ $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$ の特徴と関連ラベルを反復処理し、ミニバッチごとにモデル $f$ のパラメーターを更新します。簡単にするために、正則化は考慮しないため、トレーニングの損失を大幅に最小限に抑えます。 

$$\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n l(f(\mathbf{x}_i), y_i),$$
:eqlabel:`eq_empirical-risk-min`

$l$ は、予測の $f(\mathbf{x}_i)$ が関連付けられたラベル $y_i$ が「どれほど悪い」かを測定する損失関数です。統計学者は:eqref:`eq_empirical-risk-min`でこの用語を「経験的リスク」と呼んでいます。*経験的リスク* は、*risk* を近似するためのトレーニングデータの平均損失です。これは、真の分布 $p(\mathbf{x},y)$ から引き出されたデータの母集団全体における損失の予想値です。 

$$E_{p(\mathbf{x}, y)} [l(f(\mathbf{x}), y)] = \int\int l(f(\mathbf{x}), y) p(\mathbf{x}, y) \;d\mathbf{x}dy.$$
:eqlabel:`eq_true-risk`

ただし、実際には、通常、データの母集団全体を取得することはできません。したがって、:eqref:`eq_empirical-risk-min` の経験的リスクを最小化する*経験的リスク最小化*は、リスクを近似的に最小化することを期待して、機械学習の実用的な戦略です。 

### 共変量シフト補正
:label:`subsec_covariate-shift-correction`

データ $(\mathbf{x}_i, y_i)$ とラベル付けした依存関係 $P(y \mid \mathbf{x})$ を推定するとします。残念ながら、観測値 $\mathbf{x}_i$ は、*ターゲット分布* $p(\mathbf{x})$ ではなく、一部の*ソース分布* $q(\mathbf{x})$ から抽出されています。幸いなことに、依存関係の仮定は条件付き分布が変わらないことを意味します ($p(y \mid \mathbf{x}) = q(y \mid \mathbf{x})$)。ソースディストリビューション $q(\mathbf{x})$ が「間違っている」場合、リスクに以下の単純な ID を使用することで修正できます。 

$$
\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(y \mid \mathbf{x})p(\mathbf{x}) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(y \mid \mathbf{x})q(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})} \;d\mathbf{x}dy.
\end{aligned}
$$

言い換えると、正しい分布から導き出される確率と間違った分布から引き出される確率の比率によって、各データ例を比較検討する必要があります。 

$$\beta_i \stackrel{\mathrm{def}}{=} \frac{p(\mathbf{x}_i)}{q(\mathbf{x}_i)}.$$

各データ例$(\mathbf{x}_i, y_i)$の重み$\beta_i$を差し込むと、以下のようにモデルをトレーニングできます。
*加重経験的リスク最小化*:

$$\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n \beta_i l(f(\mathbf{x}_i), y_i).$$
:eqlabel:`eq_weighted-empirical-risk-min`

悲しいかな、私たちはその比率を知らないので、何か役に立つことをする前に、それを推定する必要があります。最小ノルムまたは最大エントロピーの原理を使用して期待演算子を直接再調整しようとする、いくつかの空想的な演算子理論的アプローチを含む、多くの方法が利用可能です。このようなアプローチでは、テストデータへのアクセスなどによる「真の」$p$ と、トレーニングセット $q$ (後者は簡単に使用可能) の生成に使用される両方の分布から抽出された標本が必要であることに注意してください。ただし、必要なのは機能 $\mathbf{x} \sim p(\mathbf{x})$ だけであり、ラベル $y \sim p(y)$ にアクセスする必要はないことに注意してください。 

この場合、元のものとほぼ同じ結果が得られる非常に効果的なアプローチが存在します。ロジスティック回帰は、バイナリ分類のソフトマックス回帰 (:numref:`sec_softmax` を参照) の特殊なケースです。推定確率比を計算するのに必要なのはこれだけです。$p(\mathbf{x})$ から引き出されたデータと $q(\mathbf{x})$ から引き出されたデータを区別する分類器を学習します。2 つのディストリビューションを区別できない場合は、関連付けられているインスタンスが 2 つのディストリビューションのいずれかに由来する可能性が等しいことを意味します。一方、十分に識別できるインスタンスは、それに応じて大幅に過大評価または過小評価する必要があります。 

簡単にするために、両方のディストリビューション $p(\mathbf{x})$ と $q(\mathbf{x})$ のインスタンス数が同じであると仮定します。$z$ ラベルで表します。ラベルは $p$ から抽出されたデータでは $1$、$q$ から抽出されたデータでは $-1$ になります。次に、混合データセットの確率は次の式で与えられます。 

$$P(z=1 \mid \mathbf{x}) = \frac{p(\mathbf{x})}{p(\mathbf{x})+q(\mathbf{x})} \text{ and hence } \frac{P(z=1 \mid \mathbf{x})}{P(z=-1 \mid \mathbf{x})} = \frac{p(\mathbf{x})}{q(\mathbf{x})}.$$

したがって、$P(z=1 \mid \mathbf{x})=\frac{1}{1+\exp(-h(\mathbf{x}))}$ ($h$ はパラメーター化された関数) というロジスティック回帰アプローチを使用すると、次のようになります。 

$$
\beta_i = \frac{1/(1 + \exp(-h(\mathbf{x}_i)))}{\exp(-h(\mathbf{x}_i))/(1 + \exp(-h(\mathbf{x}_i)))} = \exp(h(\mathbf{x}_i)).
$$

その結果、2 つの問題を解く必要があります。1 つ目は両方の分布から抽出されたデータを区別するための問題で、次に :eqref:`eq_weighted-empirical-risk-min` の加重経験的リスク最小化問題で、項を $\beta_i$ で計量します。 

これで、補正アルゴリズムを説明する準備が整いました。学習セット $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$ とラベルのないテストセット $\{\mathbf{u}_1, \ldots, \mathbf{u}_m\}$ があるとします。共変量シフトでは、すべての $1 \leq i \leq n$ の $\mathbf{x}_i$ が何らかのソース分布から抽出され、$1 \leq i \leq m$ の $\mathbf{u}_i$ がターゲット分布から抽出されると仮定します。共変量シフトを補正するための典型的なアルゴリズムを次に示します。 

1. バイナリ分類学習セット $\{(\mathbf{x}_1, -1), \ldots, (\mathbf{x}_n, -1), (\mathbf{u}_1, 1), \ldots, (\mathbf{u}_m, 1)\}$ を生成します。
1. ロジスティック回帰を使用してバイナリ分類器に学習をさせ、関数 $h$ を取得します。
1. 定数 $c$ に対して $\beta_i = \exp(h(\mathbf{x}_i))$ 以上の $\beta_i = \min(\exp(h(\mathbf{x}_i)), c)$ を使用してトレーニングデータを重み付けします。
1. :eqref:`eq_weighted-empirical-risk-min` の $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$ のトレーニングには、ウェイト $\beta_i$ を使用してください。

上記のアルゴリズムは決定的な前提に基づいていることに注意してください。このスキームを機能させるには、ターゲット (検定時間など) 分布の各データ例が学習時に発生する確率がゼロでないことが必要です。$p(\mathbf{x}) > 0$ だが $q(\mathbf{x}) = 0$ の点が見つかると、対応する重要度の重みは無限大になります。 

### ラベルシフト補正

$k$ カテゴリの分類タスクを扱っていると仮定します。:numref:`subsec_covariate-shift-correction`、$q$、$p$ で同じ表記法を使用すると、それぞれソース分布 (トレーニング時間など) とターゲット分布 (テスト時間など) になります。ラベルの分布は時間の経過とともに変化すると仮定します。$q(y) \neq p(y)$ ですが、クラス条件付き分布は同じ $q(\mathbf{x} \mid y)=p(\mathbf{x} \mid y)$ のままです。ソースディストリビューション $q(y)$ が「間違っている」場合、:eqref:`eq_true-risk` で定義されているリスク内の次の識別情報に従って修正できます。 

$$
\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(\mathbf{x} \mid y)p(y) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(\mathbf{x} \mid y)q(y)\frac{p(y)}{q(y)} \;d\mathbf{x}dy.
\end{aligned}
$$

ここで、重要度の重みはラベルの尤度比に対応します。 

$$\beta_i \stackrel{\mathrm{def}}{=} \frac{p(y_i)}{q(y_i)}.$$

ラベルシフトの良い点の 1 つは、ソース分布にかなり良いモデルがあれば、周囲の次元を処理しなくてもこれらの重みを一貫して推定できることです。ディープラーニングでは、入力は画像のような高次元のオブジェクトになりがちですが、ラベルはカテゴリなどの単純なオブジェクトであることがよくあります。 

ターゲットラベルの分布を推定するには、まず適度に優れた市販の分類器 (通常は学習データで学習済み) を使用し、検証セット (これも学習分布から) を使用して混同行列を計算します。*混同行列* $\mathbf{C}$ は単に $k \times k$ 行列で、各列はラベルカテゴリ (グラウンドトゥルース) に対応し、各行はモデルの予測カテゴリに対応します。各セルの値 $c_{ij}$ は、真のラベルが $j$ で、モデルが $i$ を予測した検証セットでの予測合計の比率です。 

複雑なリアルタイムアノテーションパイプラインに投資しない限り、実際に見られる例のラベルを見ることができないため、ターゲットデータの混同行列を直接計算することはできません。ただし、可能なことは、テスト時にすべてのモデル予測を平均して、平均モデル出力 $\mu(\hat{\mathbf{y}}) \in \mathbb{R}^k$ を生成することです。$i^\mathrm{th}$ 要素 $\mu(\hat{y}_i)$ は、モデルが $i$ を予測したテストセットでの予測全体の比率です。 

いくつかの穏やかな条件下で、分類器がそもそも適度に正確で、ターゲットデータに以前に見たカテゴリのみが含まれていて、ラベルシフトの仮定がそもそも当てはまる場合 (ここで最も強い仮定)、テストセットのラベルを推定できることがわかりました。単純な線形システムを解くことによる分布 

$$\mathbf{C} p(\mathbf{y}) = \mu(\hat{\mathbf{y}}),$$

$p(y_j)$ は $k$ 次元のラベル分布ベクトル $p(\mathbf{y})$ の $j^\mathrm{th}$ 要素であるため、$\sum_{j=1}^k c_{ij} p(y_j) = \mu(\hat{y}_i)$ は推定値としてすべての $1 \leq i \leq k$ に当てはまるためです。分類器が最初から十分に正確であれば、混同行列 $\mathbf{C}$ は可逆になり、解 $p(\mathbf{y}) = \mathbf{C}^{-1} \mu(\hat{\mathbf{y}})$ が得られます。 

ソースデータのラベルが観察されるため、分布 $q(y)$ を推定するのは簡単です。ラベルが $y_i$ のトレーニング例 $i$ について、推定した $p(y_i)/q(y_i)$ の比率を使用して重量 $\beta_i$ を計算し、これを :eqref:`eq_weighted-empirical-risk-min` の加重経験的リスク最小化にプラグインできます。 

### コンセプトシフト補正

コンセプトシフトは、原則的に修正するのがはるかに困難です。例えば、猫と犬を区別することから、白と黒の区別に問題が突然変わる状況では、新しいラベルを集めてゼロから訓練するよりもずっと良いことができると考えるのは無理です。幸いなことに、実際には、このような極端なシフトはまれです。代わりに、通常、タスクがゆっくりと変化し続けることが起こります。物事をより具体的にするために、いくつかの例を挙げます。 

* コンピュテーショナル広告では、新製品が発売され、
古い製品はあまり人気がなくなります。つまり、広告の分布とその人気は徐々に変化し、クリック率の予測因子もそれに伴って徐々に変化する必要があります。
* 交通カメラのレンズは環境摩耗により徐々に劣化し、画質に徐々に影響を与えます。
* ニュースの内容は徐々に変化する（ニュースのほとんどは変わらないが、新しい記事が出てくる）。

このような場合、ネットワークの学習に使用したのと同じアプローチを使用して、ネットワークをデータの変化に適応させることができます。つまり、ゼロから学習させるのではなく、既存のネットワークの重みを使用し、新しいデータでいくつかの更新ステップを実行するだけです。 

## 学習問題の分類学

分布の変化にどう対処するかについての知識をもって、機械学習の問題の定式化に関する他の側面についても検討できるようになりました。 

### バッチ学習

*バッチ学習* では、モデル $f(\mathbf{x})$ のトレーニングに使用するトレーニング機能とラベル $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$ にアクセスできます。その後、このモデルを展開して、同じ分布から抽出された新しいデータ $(\mathbf{x}, y)$ をスコアリングします。これは、ここで説明するすべての問題に対する既定の前提です。たとえば、猫と犬の写真をたくさん使って猫検出器をトレーニングするとします。トレーニングが完了すると、猫だけが入ることができるスマートキャットドアコンピュータビジョンシステムの一部として出荷されます。その後、これは顧客の自宅に設置され、（極端な状況を除いて）再度更新されることはありません。 

### オンライン学習

ここで、データ $(\mathbf{x}_i, y_i)$ が一度に 1 つのサンプルに到達するとします。より具体的には、最初に$\mathbf{x}_i$を観察し、次に推定$f(\mathbf{x}_i)$を考え出す必要があると仮定します。これを行うと、$y_i$を観察し、決定を下すと報酬を受け取るか損失を被ります。多くの実際の問題がこのカテゴリに分類されます。たとえば、明日の株価を予測する必要があります。これにより、その見積もりに基づいて取引できるようになり、1日の終わりに、見積もりによって利益が得られたかどうかがわかります。言い換えれば、*オンライン学習*では、新しい観察からモデルを継続的に改善しているという次のサイクルがあります。 

$$
\mathrm{model} ~ f_t \longrightarrow
\mathrm{data} ~ \mathbf{x}_t \longrightarrow
\mathrm{estimate} ~ f_t(\mathbf{x}_t) \longrightarrow
\mathrm{observation} ~ y_t \longrightarrow
\mathrm{loss} ~ l(y_t, f_t(\mathbf{x}_t)) \longrightarrow
\mathrm{model} ~ f_{t+1}
$$

### バンディッツ

*Bandits*は上記の問題の特殊なケースです。ほとんどの学習問題には、パラメーターを学習したい連続パラメーター化関数 $f$ がありますが (例:ディープネットワーク)、*bandit* 問題では、引き出すことができる腕の数は有限です。つまり、実行できるアクションの数は有限です。この単純な問題に対して、最適性の観点からより強力な理論的保証が得られることはそれほど驚くべきことではない。この問題はしばしば（紛らわしい）明確な学習環境であるかのように扱われるため、主にリストアップします。

### コントロール

多くの場合、環境は私たちが行ったことを記憶しています。必ずしも敵対的な方法ではありませんが、記憶するだけで、反応は以前に起こったことに依存します。たとえば、コーヒーボイラーコントローラーは、以前にボイラーを加熱していたかどうかによって異なる温度を観測します。PID (比例-積分-微分) コントローラーアルゴリズムは一般的な選択肢です。同様に、ニュースサイトでのユーザーの行動は、以前に表示した内容によって異なります（例えば、ほとんどのニュースを一度だけ読むなど）。このようなアルゴリズムの多くは、意思決定のランダム性を低くするように動作する環境のモデルを形成しています。最近では、制御理論 (PID バリアントなど) もハイパーパラメーターを自動的に調整し、よりよいもつれと再構成品質を実現し、生成テキストの多様性と生成画像の再構成品質を向上させるためにも使用されている :cite:`Shao.Yao.Sun.ea.2020`。 

### 強化学習

メモリのある環境のより一般的なケースでは、その環境が私たちと協力しようとしている状況（特にゼロサム以外のゲームのための協力ゲーム）や、環境が勝とうとする状況に遭遇することがあります。*強化学習*には、チェス、ゴー、バックギャモン、スタークラフトなどがあります。同様に、自動運転車用の優れたコントローラーを構築したいと思うかもしれません。他の車は、回避しようとする、事故を起こそうとする、協力しようとする、など、自明ではない方法で自動運転車の運転スタイルに反応する可能性が高い。 

### 環境を考える

上記のさまざまな状況の大きな違いの 1 つは、静止した環境の場合にずっと有効であったのと同じ戦略が、環境が適応できるときには機能しない可能性があるということです。たとえば、トレーダーが発見した裁定取引機会は、その機会を悪用し始めると消滅する可能性があります。環境が変化する速度と方法によって、私たちが耐えられるアルゴリズムの種類が大きく決まります。たとえば、物事がゆっくりとしか変化しないことがわかっている場合は、見積もりをゆっくりとしか変化させないようにすることもできます。環境が瞬時に変化する可能性があるが、ごくまれにしか変化しないことがわかっている場合は、それを考慮に入れることができます。このような知識は、意欲的なデータサイエンティストがコンセプトシフト、つまり解決しようとしている問題が時間とともに変化するときに対処するために不可欠です。 

## 機械学習における公平性、説明責任、透明性

最後に、機械学習システムを導入する際には、単に予測モデルを最適化するだけではなく、意思決定を (部分的または完全に) 自動化するためのツールを提供することになるということを覚えておくことが重要です。これらの技術システムは、結果として生じる決定の対象となる個人の生活に影響を与える可能性があります。予測の検討から意思決定への飛躍は、新しい技術的な問題だけでなく、慎重に検討しなければならない多くの倫理的問題も提起します。医療診断システムを導入する場合、どの集団に対してそれが機能し、どの集団が機能しないかを知る必要があります。亜集団の福祉に対する予測可能なリスクを見落とすと、私たちは劣悪なケアを受ける可能性があります。さらに、いったん意思決定システムを熟考したら、一歩下がってテクノロジーの評価方法を見直さなければなりません。この範囲の変更による他の結果の中でも、*正確さ*が適切な尺度になることはめったにありません。たとえば、予測をアクションに変換する場合、エラーがもたらす潜在的なコスト感受性をさまざまな方法で考慮することがよくあります。画像を誤分類する1つの方法が人種的な手先として認識され、別のカテゴリへの誤分類が無害である場合は、意思決定プロトコルの設計における社会的価値を考慮して、それに応じてしきい値を調整する必要があります。また、予測システムがどのようにフィードバックループにつながるかについても注意が必要です。たとえば、犯罪が予測されるエリアに巡回担当者を割り当てる予測ポリシングシステムを考えてみましょう。心配なパターンがどのように現れるかは簡単にわかります。 

 1. 犯罪の多い地域では、パトロールが増えます。
 1. その結果、これらの近傍でより多くの犯罪が発見され、今後の反復に使用できるトレーニングデータが入力されます。
 1. より多くの陽性にさらされたこのモデルは、これらの近傍でさらに多くの犯罪を予測しています。
 1. 次のイテレーションでは、更新されたモデルが同じ近傍をさらにターゲットにしているため、さらに多くの犯罪が発見されるなどです。

多くの場合、モデルの予測がトレーニングデータに結合されるさまざまなメカニズムは、モデリングプロセスでは考慮されません。これは、研究者が「暴走フィードバックループ」と呼ぶものにつながる可能性があります。また、そもそも正しい問題に取り組んでいるかどうかについても注意が必要です。現在、予測アルゴリズムは、情報の伝達を仲介する上で非常に大きな役割を果たしています。個人が遭遇するニュースは、彼らが*いいね*したFacebookページのセットによって決定されるべきですか？これらは、機械学習のキャリアで遭遇する可能性のある、差し迫った倫理的ジレンマのほんの一部です。 

## [概要

* 多くの場合、学習セットとテストセットは同じ分布に由来しません。これを配分シフトといいます。
* リスクとは、真の分布から引き出されたデータの母集団全体に対する損失の予測です。ただし、この全人口は通常利用できません。経験的リスクは、リスクを近似するためのトレーニングデータに対する平均損失です。実際には、経験的リスク最小化を行っています。
* 対応する仮定の下で、共変量とラベルシフトを検出し、検定時に補正できます。このバイアスを考慮しないと、テスト時に問題が生じる可能性があります。
* 場合によっては、環境が自動化されたアクションを記憶し、意外な方法で反応することがあります。モデルを構築する際には、この可能性を考慮し、モデルと環境が予期せぬ方法で絡み合う可能性を考慮して、ライブシステムを監視し続ける必要があります。

## 演習

1. 検索エンジンの動作を変更するとどうなるでしょうか？ユーザーは何をしますか？広告主はどうですか？
1. 共変量シフト検出器を実装します。ヒント:分類器を構築します。
1. 共変量シフト補正器を実装します。
1. 分配シフト以外に、経験的リスクがどのようにリスクに近似するかに影響する可能性のあるものは他にありますか？

[Discussions](https://discuss.d2l.ai/t/105)
