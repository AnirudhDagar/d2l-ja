# 付録:ディープラーニングのための数学
:label:`chap_appendix_math`

**ブレント・ウェルネス** (*Amazon*)、**Rachel Hu** (*Amazon*)、およびこの本の著者

現代のディープラーニングの素晴らしい部分の1つは、その下にある数学を完全に理解しなくても理解して使用できるという事実です。これは畑が成熟している兆候です。ほとんどのソフトウェア開発者が計算可能関数の理論について心配する必要がなくなったように、ディープラーニングの実践者は最尤学習の理論的基礎について心配する必要もありません。 

しかし、私たちはまだそこにいません。 

実際には、アーキテクチャの選択が勾配流にどのように影響するか、または特定の損失関数を使用して学習することによって行う暗黙的な仮定を理解する必要がある場合があります。ワールドでエントロピーが何を測定するのか、そしてそれがモデルにおける文字あたりのビット数の意味を正確に理解するのにどのように役立つのかを知る必要があるかもしれません。これらはすべて、より深い数学的理解が必要です。 

この付録は、現代のディープラーニングのコア理論を理解するために必要な数学的背景を提供することを目的としていますが、すべてを網羅しているわけではありません。まず、線形代数をさらに深く調べることから始めます。一般的な線形代数オブジェクトと演算の幾何学的理解を深め、さまざまな変換がデータに及ぼす影響を視覚化できるようにします。重要な要素は、固有分解の基礎の開発です。 

次に、勾配が最も急な降下方向である理由と、逆伝播がその形式をとる理由を完全に理解できるように、微分計算の理論を発展させます。次に、次のトピックである確率論をサポートするために必要な程度まで、積分計算について議論します。 

実際に頻繁に遭遇する問題は定かではなく、不確かなことを話すための言葉が必要です。確率変数の理論と最も一般的に遭遇する分布を復習し、モデルを確率論的に議論します。これは、確率的分類手法である単純ベイズ分類器の基礎となります。 

確率論と密接に関連しているのは統計学の研究です。統計学は短編では正義を行うには大きすぎる分野ですが、すべての機械学習者が知っておくべき基本的な概念、特に推定量の評価と比較、仮説検定の実施、信頼区間の構築について紹介します。 

最後に、情報の保存と伝達の数学的研究である情報理論の話題に目を向ける。これは、モデルが談話の領域でどのくらいの情報を保持しているかを定量的に議論するためのコア言語を提供します。 

これらをまとめると、ディープラーニングを深く理解するための道を歩むために必要な数学的概念の中核を形成します。

```toc
:maxdepth: 2

geometry-linear-algebraic-ops
eigendecomposition
single-variable-calculus
multivariable-calculus
integral-calculus
random-variables
maximum-likelihood
distributions
naive-bayes
statistics
information-theory
```
